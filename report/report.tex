\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{listings}
\usepackage{color}

\title{AlphaBiscuit - Image Recognition of Letter Biscuits}
\author{Arash Rouhani}

\begin{document}

\maketitle

\begin{abstract}
    Letter biscuits have been around for many decades, but digital image
analysis are only beginning to find applications in the real world.
Typing with letter biscuits is joyful for children, using image analysis
one could create electronical activities that involves these biscuits,
such activities could improve literacy among children. This paper take
a statistical approach to automatically classify alphabet biscuits,
applying known techniques from image analysis. Using the classifier, we
then create a word reader that extracts words from an image of letter
biscuits.

\end{abstract}

\section{Introduction}
The recognition of letter biscuits is similiar to many other image recognition problems.
Image recognition being well developed already, only little new research have been made for this project.
Rather, a way to combine existing techniques will be presented.

In order to optimize our recognition method, some remarks should be made on the type of data we are working with.
To our favour, the biscuits are manufactured, and therfor all biscuits of the same letter looks the same, both in shape and color. 
On the other hand the solid body form of biscuits can surpress distinguishable characteristics. For example, the hole in the letter A is small, perhaps unnoticeable, due to the overall thickness of the biscuits. Another problem, when dealing with letter recognition in general is the multitude of letters to identify from.

The identification process is a standard composition of image processing concepts. Segmenting, collecting features and then classifying.
initially we segment a picture to a black and white image containing only the biscuits, 
we then collect features from the segmented image. 
The classification is based on the features, we classify the unkown biscuit by comparing its features to a set of known biscuits.
In case of there being several biscuits in the image, a wordizer will organize the letters and read out the word.

The segmentation process is well studied for \emph{general} objects, but the fact that the biscuits are of the same colors must be used.
One challenge is to develop our own segmentation method.
The method created for biscuit segmentation could also be used for other segmentation purposes where the data is having similiar properties.

\section{Data collection}
Initially, a low quality camera (mobile camera) was used to photograph all the images.
Later this was changed to use a much better camera with more organized photography.
The biscuits are laid on a blank white paper, so the whole background is white when photographing, this avoids to catch anything with simliar colors as the biscuits on the image, as that would distract the segmenter.
All the biscuits used are from the commercial brand named BRAGO BOKSTAVSKEX.
Figure \ref{fig:unprocessed} contains three photographed images used throughout this paper.

\begin{figure}[]
\begin{center}
\includegraphics[width=40mm]{orig_a.JPG}
\includegraphics[width=40mm]{orig_i.JPG}
\end{center}
\caption{Three unprocessed images}
\label{fig:unprocessed}
\end{figure}

Among the biscuits, there are only capital letters present. A few letters are missing.
There are totally $177$ images of single biscuits that the classifier trained on.
Figure \ref{fig:alphabet} shows all the characters present in the data.

\begin{figure}[]
\begin{center}
\includegraphics[width=140mm]{alphabet.JPG}
\end{center}
\caption{An image of all the character types present in the data set}
\label{fig:alphabet}
\end{figure}

\section{Segmentation}

When studying the biscuits as an \emph{object},
it's clear that the biscuits are only of one color,
but when studying images of biscuits, 
the pixels corresponding to the biscuit varies in color because of different lightning.
As humans this don't bother us, we automatically segment objects apart.
In image analysis, segmenting means to decide which pixels are actually of interest to us.
There are many known segmentation methods available.
And they work differently good for different segmentation tasks.

We want a segmentation method that uses the fact that the biscuits are of the same color.
One sensible segmentation method is to define a set of the RGB-colors representing usable colors.
That means pixels are interesting only if its color is in the set.

In this project, we implemented sementation with the above mentioned idea in mind.
Since it worked sufficiently well, we did not examine more possibilites. 
\emph{Thresholding} can quite easily implement the set idea in practice.

\subsection{Thresholding}
We threshold directly on the color image, treating each pixel individually. 
That means that we don't threshold on greycolor images,
neither do we turn a color image into greyscale as an intermediete step.

With expressfulness over the three color channels, 
we can easily define a reasonable set of biscuit-colors.
The biscuits are always more red than green, and always more green than blue.
With threholding this property can be easily stated as $r>g>b$.
The exact mathematical thresholding used in our implementation is $ r > 50 & 30 < g < 200 & b < 150 & r > 1.2*g & g > 1.2*b $.



\begin{figure}[]
\begin{center}
\includegraphics[width=40mm]{seg_a.JPG}
\includegraphics[width=40mm]{seg_i.JPG}
\includegraphics[width=40mm]{seg_word.JPG}
\end{center}
\caption{Three segmented images using thresholding}
\label{fig:segmented}
\end{figure}


\section{Features}
We considered to use the following features
\begin{itemize}
\item Major Axis Length
\item Solidity - Also called convexity
\item Momentum - An easily turnable (easy for a given mass) object has a high momentum, for example the letter I. Momentum is calculated by summing for each pixel it's distance from the center-weight. The momentum feature can be measured for different exponents on the distance for each pixel. We used three features of this kind with the exponents 1,2 and 3.
\item Eccentricity
\item Perimetry
\item Number of holes - An \emph{A} has one hole, but a \emph{B} has two holes.
\end{itemize}
It should be noted that the feature Number of holes isn't failproof,
since bad segmentation can create small holes, or cover actual holes.
\subsection{Feature normalization}
The features presented above are incomparable to each other.
When MajorAxisLength have been normalized with respect to the area, 
it can be compared to another MajorAxisLength value, 
even though the zooming of the pictures are not the same. 
However, the feature MajorAxisLength is incompariable to features of a different type.

In the configuration in table \ref{tab:features}, it's clear that the Solidity reveals that the biscuits
are different, the MajorAxisLength are however not to different.
However, when naively comparing by subtraction, MajorAxisLength has a bigger difference.
To battle this behavior we use the \emph{linear scaling with unit variance} normalization, see equation \ref{eqn:univariance} (Aksoy and Haralick, 2000).

\begin{table}[h!b!p!]
\caption{Two features of two biscuits}
\begin{center}
    \begin{tabular}{ l | c | c | }
                    & Biscuit 1 & Biscuit 2 \\ \hline
    MajorAxisLength & 7.0       & 8.5       \\ \hline
    Solidity        & 0.11      & 0.9       \\ \hline
    \end{tabular}
\end{center}
\label{tab:features}
\end{table}

\begin{equation}
x_{new} = \frac{x - \mu}{\sigma}
\label{eqn:univariance}
\end{equation}

After this transformation, all features have a mean of $0$ and variance of $1$.
Now it's more senseful to compare two different features, or to take the euclidean distance between two biscuits (set of features).
\subsection{Feature selection}
With feature normalization taken in place, there is yet no weighting of the features,
perhaps a large difference in MajorAxisLength definetly tells two biscuits apart,
meanwhile a large difference in Solidity sould be considered less significant.

We do partially adress this problem by using \emph{binary} weights on the features, 
that is equivelent to simply not using some features.
This is helpful when a feature is having a negative impact on the overall classification.
We use the \emph{greedy backward elimination} method in our feature selection.
\section{Classifying unknown biscuits}
Classification, in our case, is to determine the letter of an unkown biscuit, given the features of manually classified biscuits.

We use the simple \emph{Nearest Neighbour} classifier, with distance defined as the euclidean distance.

\section{Wordizer}
If an image contains many letters, the letters are often representing words.
The wordizer is sweeping through the letters and makes one sentence with the letters by examining the positions of each letter.
If visually clear enough, the wordizer will put whitespace (spaces and newlines) in the sentence where appropriate.
\section{Results}
The result section will show the results of a cross-validation process, look at a failing example and end with a section about reading out a word image.
\subsection{Cross-validation}
Given the data described, using the classification methods mentioned, we ran the backwards-elimination process.
Starting with the features listed in the features section, table \ref{tab:backelim} shows what features
where eliminated and for what gain using backwards-elimination.
The CV-value is the ratio of correctly identified biscuits using cross validation.


\begin{table}[h!b!p!]
\caption{Backwards elimination}
\begin{center}
    \begin{tabular}{ l | c | c | }
    Feature         & Previous CV-value \\ \hline
    Solidity        & 97.18\%           \\ \hline
    Number of holes & 97.77\%           \\ \hline
    \end{tabular}
\end{center}
\label{tab:backelim}
\end{table}

So the final feature configuration became: Perimetry, Eccentricity and the three versions of momentum.
That configuration gave us a CV-value of $98.87\%$.

Running the same procedure on a slightly reduced character-set without å, ä and ö,
the final feature configuration is $ Perimetry, Eccentricity, Solidity  and momentum with exponent one$ and has a CV-value of exactly $100\%$. 


\subsection{Wordizing the alphabet}
Wordizing the Image in figure \ref{fig:alphabet} gives the following output:
... output ...
\texttt{
dkxåhing
hxn äåx
uäunted
men
}
\texttt{
dkeaming
hen are
uaunted
men
}








\section{Discussion}

Even though simplicity in segmentation, feature extraction and especially classification, the results was good.
However, the input images are friendly to work with,
there is no deliberate noise, the lightning is constantified by the use of camera lightning and the camera was put stable on a tripod.
An undocumented experiment showed a CV-value of about 85\% as best with the old data-set 

The feature elimination seem quite untrustworthy,
with a quite tiny modification in the data set,
a quite different set of features was suggested by backwards-elimination.
This might be due to that with the full data-set,
quite a lot of the effort of the backwards-elimination was to minimize frequent a, å and ä clashes.
But with a data-set without such worries, the elimination focused on smaller details.
Thus eliminating diffrently for the similiar data-sets.

\section{References}
\section{Appendice}


\end{document}
